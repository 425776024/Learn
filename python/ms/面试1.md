## *args. **kwargs
```
*args用来表示函数接收可变长度的非关键字参数列表作为函数的输入。
**kwargs表示函数接收可变长度的关键字参数字典作为函数的输入。

*args表示任何多个无名参数，它是一个tuple；**kwargs表示关键字参数，它是一个dict。并且同时使用*args和**kwargs时，必须*args参数列要在**kwargs前

*args和**kwargs一般是用在函数定义的时候。二者的意义是允许定义的函数接受任意数目的参数。
也就是说我们在函数被调用前并不知道也不限制将来函数可以接收的参数数量。
在这种情况下我们可以使用*args和**kwargs。
```

## 常用模块
```
import os,re, sys, copy, json, uuid, socket, base64, random, urllib, requests, redis, itertools, collections, operator, functools, threading
```

## 内置的数据结构。
```
可以类型：列表 list、字典 dict、 集合 set
不可变类型： 元组 tuple、 整数 int、 长整形 long、 浮点数 float、 复数 complex、 字符串 str
```

## is 和 == 有什么区别？
```
is就是用来判断两个变量的id是否相等，当两个变量的id相等时，说明这两个变量指向的地址是相同的，那么这两个变量的一切属性都相同。
is比较的是两个对象的id值是否相等，也就是比较两个对象是否为同一个实例对象，是否指向同一个内存地址。
==比较的是两个对象的内容是否相等，默认会调用对象的__eq__()方法。

python为了实现对内存的有效利用，对小整数[-5,256]内的整数会进行缓存，不在该范围内的则不会缓存
引用也指向同一块内存。

Python中对象包含的三个基本要素，分别是：id(身份标识)、type(数据类型)和value(值)。对象之间比较是否相等可以用==，也可以用is。
is和==都是对对象进行比较判断作用的，但对对象比较判断的内容并不相同。
```

## 函数
```
函数参数不能使用默认列表，因为新的默认列表只在函数被定义的那一刻创建一次。
python闭包的延迟绑定，注意调用正确。
```

## Lambda 函数
```
Lambda 函数又称匿名函数，匿名函数就是没有名字的函数.

闭包本身是一个晦涩难懂的概念，我们可以简单粗暴地理解为闭包就是一个定义在函数内部的函数，
闭包使得变量即使脱离了该函数的作用域范围也依然能被访问到:
>>> def my_add(n):
...     return lambda x:x+n
...
>>> add_3 = my_add(3)
>>> add_3(7)
10
```

## 闭包  什么是闭包？闭包有什么用？为什么要用闭包？
```
闭包概念：在一个内部函数中，对外部作用域的变量进行引用，(并且一般外部函数的返回值为内部函数)，那么内部函数就被认为是闭包。

函数身为第一类对象，它可以作为函数的返回值返回

import time
def closure():
    a = [0]
    def inner():
        tmp = a[0]
        if a[0]>=10:
            a[0] = 0
            return tmp
        a[0] += 1
        return tmp
    return inner

c = closure()
while 1:
    print c()
    time.sleep(0.1)

def point(x, y):
    def get_distance(u, v):
        return sqrt((x - u) ** 2 + (y - v) ** 2)

    return get_distance

>>> pt = point(7, 2)
>>> pt(10, 6)
5.0

def adder(x):
    def wrapper(y):
        return x + y
    return wrapper

adder5 = adder(5)
print adder5(10)
# 输出 15
print adder5(6)
# 输出 11

所有函数都有一个 __closure__属性，如果这个函数是一个闭包的话，那么它返回的是一个由 cell 对象 组成的元组对象。
cell 对象的cell_contents 属性就是闭包中的自由变量。
>>> adder.__closure__
>>> adder5.__closure__
(<cell at 0x103075910: int object at 0x7fd251604518>,)
>>> adder5.__closure__[0].cell_contents
5
# 闭包的作用
- 闭包的最大特点就是引用了自由变量，即使生成闭包的环境已经释放，闭包仍然存在。
- 闭包在运行时可以有多个实例，即使传入的参数相同。
```

## 装饰器，装饰器的执行顺序。
```
from functools import wraps
def cache(func):

    caches = {}
    @wraps(func)
    def wrap(*args):
        if args not in caches:
            caches[args] = func(*args)
        return caches[args]
    return wrap

@cache
def fib(num):
    if num < 2:
        return 1
    return fib(num-1) + fib(num-2)

for i in range(10):
    print fib(i)
    
- 本质上，装饰器就是一个返回函数的高阶函数。
- 装饰器可以动态地修改一个类或函数的功能，通过在原有的类或者函数上包裹一层修饰类或修饰函数实现。
- 事实上，装饰器就是闭包的一种应用，但它比较特别，接收被装饰函数为参数，并返回一个函数，赋给被装饰函数，闭包则没这种限制。

class MakeTag(object):
    def __init__(self, tag):
        self.tag = tag

    def __call__(self, func):
        def wrapped(*args, **kwargs):
            return "<{tag}>{res}</{tag}>".format(
                res=func(*args, **kwargs), tag=self.tag
            )
        return wrapped
        
import functools
def MakeTag(tag=None):
    def _maketag(func):
        @functools.wraps(func)
        def wrapped(*args, **kwargs):
            return "<{tag}>{res}</{tag}>".format(
                res=func(*args, **kwargs), tag=tag
            )
        return wrapped
    return _maketag

@MakeTag(tag='p')
@MakeTag(tag='b')
def hello(name):
    return 'hello %s' % name

print hello('world')
# <p><b>hello world</b></p>
```

## 装饰器的执行顺序
```
from functools import wraps
def dec_a(func):
    print("   top a")
    @wraps(func)
    def wrapped(*args, **kwargs):
        print(" inner a")
        return "a|{}".format(func(*args, **kwargs))
    print("return a")
    return wrapped

def dec_b(func):
    print("   top b")
    @wraps(func)
    def wrapped(*args, **kwargs):
        print(" inner b")
        return "b|{}".format(func(*args, **kwargs))
    print("return b")
    return wrapped

@dec_b
@dec_a
def test():
    return "test"

s = test()
print s


   top a
return a
   top b
return b
 inner b
 inner a
b|a|test
前面四行是编译的函数的时候执行顺序

后面三行相当于 dec_b(dec_a(test()))
```

## 动态的获取、设置对象的属性
```hasattr、getattr、setattr、delattr```

## 类方法、类实例方法、静态方法 区别
```
>> 1. 实例方法：通过def定义的 普通的一般的，需要至少传递一个参数，一般用self，这样的方法必须通过一个类的实例去访问，类似于c++中通过对象去访问；
>> 2. 类方法：在def前面加上@classmethod，这种类方法的一个特点就是可以通过类名去调用，但是也必须传递一个参数，一般用cls表示class，表示可以通过类直接调用；
>> 3. 静态方法： 在def前面加上@staticmethod，这种类方法是静态的类方法，类似于c++的静态函数，他的一个特点是参数可以为空，同样支持类名和对象两种调用方式；

普通的方法，第一个参数需要是self，它表示一个具体的实例本身。
如果用了staticmethod，那么就可以无视这个self，而将这个方法当成一个普通的函数使用。
而对于classmethod，它的第一个参数不是self，是cls，它表示这个类本身。

一般来说，要使用某个类的方法，需要先实例化一个对象再调用方法。
而使用@staticmethod或@classmethod，就可以不需要实例化，直接类名.方法名()来调用。
这有利于组织代码，把某些应该属于某个类的函数给放到那个类里去，同时有利于命名空间的整洁。

既然@staticmethod和@classmethod都可以直接类名.方法名()来调用，那他们有什么区别呢
从它们的使用上来看,
---- @staticmethod不需要表示自身对象的self和自身类的cls参数，就跟使用函数一样。
---- @classmethod也不需要self参数，但第一个参数需要是表示自身类的cls参数。
如果在@staticmethod中要调用到这个类的一些属性方法，只能直接类名.属性名或类名.方法名。
而@classmethod因为持有cls参数，可以来调用类的属性，类的方法，实例化对象等，避免硬编码。
```

## 浅复制、深复制
```可变对象的复制是引用。```

## 单例模式
```
使用__new__:
class Singleton(object):
    _instance = None
	
    def __new__(cls, *args, **kw):
        if not cls._instance:
            cls._instance = super(Singleton, cls).__new__(cls, *args, **kw)
        return cls._instance

class MyClass(Singleton):

	def __init__(self, name):
		self.name = name

a = MyClass(1)
b = MyClass(2)

print id(a), id(b)
print a.name, b.name

# 38727920 38727920
# 2 2

装饰器模式：
from functools import wraps

def singleton(cls):
	_instance = {}
	@wraps(cls)
	def wrapped(*args, **kwargs):
		if cls not in _instance:
			_instance[cls] = cls(*args, **kwargs)
		return _instance[cls]
	return wrapped

@singleton
class MyClass(object):
	def __init__(self, name):
		self.name = name

a = MyClass(1)
b = MyClass(2)

print id(a), id(b)
print a.name, b.name

# 38727920 38727920
# 1 1

元类模式：
class Singleton(type):
    _instances = {}
    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)
        return cls._instances[cls]

class MyClass(object):
	__metaclass__ = Singleton

	def __init__(self, name):
		self.name = name

a = MyClass(1)
b = MyClass(2)

print id(a), id(b)
print a.name, b.name

# 38727920 38727920
# 1 1
```

## python中的变量作用域（查找顺序）
```
LEGBlocal局部变量 -》enclosed闭包作用域 -》 Global 全局变量 -》built-in 全局变量
```

## 静态变量
```
# -*- coding: utf-8 -*-
class Parent(object):
	x= 1
class Child1(Parent):
	pass
class Child2(Parent):
	pass

print Parent.x, Child1.x, Child2.x
# 输出：1，1，1 继承自父类的类属性，所以都一样，指向都一块内存地址。

Child1.x = 2
print Parent.x, Child1.x, Child2.x
# 输出：1，2，1 更改Child1，Child1的x指向了新的内存地址。

Parent.x = 3
print Parent.x, Child1.x, Child2.x
# 输出：3，2，3 更改Parent，Parent的x指向了新的内存地址，而Child2跟着Parent改变。
```

## 异常
```
总结如下: 
1. except语句不是必须的，finally语句也不是必须的，但是二者必须要有一个，否则就没有try的意义了。
2. except语句可以有多个，Python会按except语句的顺序依次匹配你指定的异常，如果异常已经处理就不会再进入后面的except语句。
3. except语句可以以元组形式同时指定多个异常，参见实例代码。
4. except语句后面如果不指定异常类型，则默认捕获所有异常，你可以通过logging或者sys模块获取当前异常。
5. 如果要捕获异常后要重复抛出，请使用raise，后面不要带任何参数或信息。
6. 不建议捕获并抛出同一个异常，请考虑重构你的代码。
7. 不建议在不清楚逻辑的情况下捕获所有异常，有可能你隐藏了很严重的问题。
8. 尽量使用内置的异常处理语句来 替换try/except语句，比如with语句，getattr()方法。

try except else finally有return时执行顺序探究：
因为有异常发生，所以try中的return语句肯定是执行不到的，然后在捕获到的except中进行执行，
并且except中存在return 语句，那么是不是就直接返回？ 因为finally 语句是必须要执行的，
所以这里的return语句需要先暂且放下，进入finally进行执行，然后finnaly执行完以后再返回到 except中进行执行。
看到这里，我们貌似找到了一些规律
1. 如果没有异常发生， try中有return 语句， 这个时候else块中的代码是没有办法执行到的， 
   但是finally语句中如果有return 语句会修改最终的返回值， 我个人理解的是try中return 语句先将要返回的值放在某个 CPU寄存器，
   然后运行finally语句的时候修改了这个寄存器的值，最后在返回到try中的return语句返回修改后的值。
2. 如果没有异常发生， try中没有return语句，那么else块的代码是执行的，但是如果else中有return， 
   那么也要先执行finally的代码， 返回值的修改与上面一条一致。
3. 如果有异常发生，try中的return语句肯定是执行不到， 在捕获异常的 except语句中，如果存在return语句，
   那么也要先执行finally的代码，finally里面的代码会修改最终的返回值，然后在从 except 块的retrun 语句返回最终修改的返回值， 和第一条一致。
```

## 那些操作会导致python内存溢出，怎么处理？
```
1. 被退出才回收的对象引用
2. 交叉引用、循环引用。
```

## python的内存管理机制以及调优手段。
```
- [python性能优化](https://www.cnblogs.com/xybaby/p/6510941.html)
- [Python内存优化：Profile，slots，compact dict](https://www.cnblogs.com/xybaby/p/7488216.html)

Python使用引用计数和垃圾回收来做内存管理
Python内存优化：Profile，slots，compact dict
```

## 内存泄漏是什么？如何避免？

## 生成器、迭代器
```
- [Iterables vs. Iterators vs. Generators](https://foofish.net/iterators-vs-generators.html)
迭代器：
迭代是Python最强大的功能之一，是访问集合元素的一种方式。
迭代器是一个可以记住遍历的位置的对象。
迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。
迭代器有两个基本的方法：iter() 和 next()。
字符串，列表或元组对象都可用于创建迭代器。

生成器：
在 Python 中，使用了 yield 的函数被称为生成器（generator）。
跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。
在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。
调用一个生成器函数，返回的是一个迭代器对象。

包含有yield的函数，都是一个生成器！
yield的语法规则是：在yield这里暂停函数的执行，并返回yield后面表达式的值（默认为None），直到被next()方法再次调用时，从上次暂停的yield代码处继续往下执行。

class MyNumbers:
    def __iter__(self):
        self.a = 1
        return self

    def next(self):
        if self.a <= 20:
            x = self.a
            self.a += 1
            return x
        else:
            raise StopIteration

for x in MyNumbers():
  print(x)

# 大文件读取
def read_in_chunks(file_obj, chunk_size = 2048):
    """
    逐件读取文件
    默认块大小：2KB
    """
    while True:
        data = file_obj.read(chunk_size)  # 每次读取指定的长度
        if not data:
            break
        yield data

def read_bigfile(filename):
    content = ""
    with open(filename, 'rb') as f:
        for chunk in read_in_chunks(f):
            content += chunk
    return content
```

## GIL, 以及对python多线程的影响。写一个多线程的程序。
```
GIl：全局解释器锁。
每个线程在执行的过程都需要先获取GIL，保证同一时刻只有一个线程可以执行字节码。

线程释放GIL锁的情况：
在IO操作等可能会引起阻塞的system call之前，可以暂时释放GIL，但在执行完毕后，必须重新获取GIL。
python 3.x使用计时器（执行时间达到阙值后，当前线程释放GIL），python2.x,tickets 技术达到100。

python使用多进程是可以利用多核CPU资源的。多线程爬取比单线程性能有提升，因为遇到IO阻塞会自动释放GIL锁。

程序：
# -*- coding: utf-8 -*-
import threading
import requests

class MyThread(threading.Thread):
    def __init__(self):
        threading.Thread.__init__(self);

    def run(self):
		requests.get(url)
        print "I am %s" %self.name


if __name__ == "__main__":
    for thread in range(0, 5):
        t = MyThread()
        t.start()
```

## 协程与异步IO
```
通常在Python中我们进行并发编程一般都是使用多线程或者多进程来实现的，
对于CPU计算密集型任务由于GIL的存在通常使用多进程来实现，
而对于IO密集型任务可以通过线程调度来让线程在执行IO任务时让出GIL，从而实现表面上的并发。

其实对于IO密集型任务我们还有一种选择就是协程。
协程，又称微线程，英文名Coroutine，是运行在单线程中的“并发”，
协程相比多线程的一大优势就是省去了多线程之间的切换开销，获得了更高的运行效率。
Python中的异步IO模块asyncio就是基本的协程模块。

Python中的协程经历了很长的一段发展历程。
最初的生成器yield和send()语法，然后在Python3.4中加入了asyncio模块，引入@asyncio.coroutine装饰器和yield from语法，
在Python3.5上又提供了async/await语法，目前正式发布的Python3.6中asynico也由临时版改为了稳定版。

Python并发编程协程(Coroutine)之Gevent

1. 协程：
协程的切换不同于线程切换，是由程序自身控制的，没有切换的开销。
协程不需要多线程的锁机制，因为都是在同一个线程中运行，所以没有同时访问数据的问题，执行效率比多线程高很多。

因为协程是单线程执行，那怎么利用多核CPU呢？
最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。

如果你还无法理解协程的概念，那么可以这么简单的理解：
进程/线程：操作系统提供的一种并发处理任务的能力。
协程：程序员通过高超的代码能力，在代码执行流程中人为的实现多任务并发，是单个线程内的任务调度技巧。

多进程和多线程体现的是操作系统的能力，
而协程体现的是程序员的流程控制能力。
看下面的例子，甲，乙两个工人模拟两个工作任务交替进行，在单线程内实现了类似多线程的功能。
```

## 协成、线程、进程的区别。
```
进程和协程不同点：
1. 执行流的调度者不同，进程是内核调度，而协程是在用户态调度，也就是说进程的上下文是在内核态保存恢复的，而协程是在用户态保存恢复的，很显然用户态的代价更低
2. 进程会被强占，而协程不会，也就是说协程如果不主动让出CPU，那么其他的协程，就没有执行的机会。
3. 对内存的占用不同，实际上协程可以只需要4K的栈就足够了，而进程占用的内存要大的多
4. 从操作系统的角度讲，多协程的程序是单进程，单协程

线程和协程：
1. 线程之间需要上下文切换成本相对协程来说是比较高的，尤其在开启线程较多时，但协程的切换成本非常低。
2. 同样的线程的切换更多的是靠操作系统来控制，而协程的执行由我们自己控制
3. 协程只是在单一的线程里不同的协程之间切换，其实和线程很像，线程是在一个进程下，不同的线程之间做切换，这也可能是协程称为微线程。

- [Python进程、线程、协程概念](https://zhuanlan.zhihu.com/p/43373955)
- [Python进程、线程、协程的对比](https://www.jianshu.com/p/0ec911909dff)
- [python进程和线程、协程的区别](https://www.jianshu.com/p/3dcad9926073)
- [python中多进程+协程的使用以及为什么要用它](https://blog.csdn.net/lambert310/article/details/51162634)
- [并发技术](https://hit-alibaba.github.io/interview/basic/arch/Concurrency.html)

1. 执行过程
每个线程有一个程序运行的入口、顺序执行序列和程序的出口。
但是线程不能够独立执行，必须依存在进程中，由进程提供多个线程执行控制。
每个线程都有他自己的一组CPU寄存器，称为线程的上下文，该上下文反映了线程上次运行该线程的CPU寄存器的状态。
协程，又称微线程，Coroutine。执行过程中，在子程序内部可中断，
然后转而执行别的子程序，在适当的时候再返回来接着执行。
实际上就是对函数调用流程的一种控制方式，让函数互相协作配合，这就是协程。

2. 调度方式
进程和线程完全由操作系统负责调度，程序自己不能决定什么时候执行，执行多长时间。
协程则是在程序中，自己负责调度，更加灵活，但复杂度较高。

3. 运行效率
进程是重量级别的程序，创建和销毁开销大。
线程是轻量级别的程序，相比进程下创建和销毁开销小，切换速度较快。
协程则是单线程的异步编程模型。
和多线程比，线程数量越多，CPU就会花掉更多时间在切换中，
而没有线程切换、保存上下文的开销的协程，相比下运行效率则更高。
第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，所以协程性能优势更加明显。

4. CPU利用
线程和协程由于CPython中全局解释器锁GIL的问题，只能使用到单核CPU的计算资源
进程则可以运行多个（数量与CPU核心数相同），充分利用多核CPU
CPython解释器本身不是线程安全的，因此需要全局解释器锁GIL，一次只允许一个线程执行Python字节码。
因此一个Python进程不能同时使用到多个CPU核心。
然而，标准库中所有执行阻塞型 IO 操作的函数，在等待结果返回时都会释放GIL。
这意味着尽管有GIL，Python线程还是能在 IO 密集型任务中一展身手。 引用自《流畅的Python》

5. 最佳实践
线程和协程推荐在IO密集型的任务(比如网络调用)中使用，而在CPU密集型的任务中，表现较差。
对于CPU密集型的任务，则需要多个进程，绕开GIL的限制，利用所有可用的CPU核心，提高效率。
所以大并发下的最佳实践就是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。
顺便一提，非常流行的一个爬虫框架Scrapy就是用到异步框架Twisted来进行任务的调度，这也是Scrapy框架高性能的原因之一。
```

## tcp/ip  简要介绍三次握手和四次挥手
```
- [TCP协议](https://hit-alibaba.github.io/interview/basic/network/TCP.html)
- [TCP协议中的三次握手和四次挥手（图解）](https://blog.csdn.net/whuslei/article/details/6667471)
建立TCP需要三次握手才能建立，而断开连接则需要四次握手。

三次握手(Three-way Handshake)：
所谓三次握手(Three-way Handshake)，是指建立一个 TCP 连接时，需要客户端和服务器总共发送3个包。
三次握手的目的是连接服务器指定端口，建立 TCP 连接，并同步连接双方的序列号和确认号，交换 TCP 窗口大小信息。在 socket 编程中，客户端执行 connect() 时。将触发三次握手。

第一次握手(SYN=1, seq=x):
客户端发送一个 TCP 的 SYN 标志位置1的包，指明客户端打算连接的服务器的端口，以及初始序号 X,保存在包头的序列号(Sequence Number)字段里。
发送完毕后，客户端进入 SYN_SEND 状态。

第二次握手(SYN=1, ACK=1, seq=y, ACKnum=x+1):
服务器发回确认包(ACK)应答。即 SYN 标志位和 ACK 标志位均为1。
服务器端选择自己 ISN 序列号，放到 Seq 域里，同时将确认序号(Acknowledgement Number)设置为客户的 ISN 加1，即X+1。 
发送完毕后，服务器端进入 SYN_RCVD 状态。

第三次握手(ACK=1，ACKnum=y+1)
客户端再次发送确认包(ACK)，SYN 标志位为0，ACK 标志位为1，并且把服务器发来 ACK 的序号字段+1，放在确定字段中发送给对方，并且在数据段放写ISN的+1
发送完毕后，客户端进入 ESTABLISHED 状态，当服务器端接收到这个包时，也进入 ESTABLISHED 状态，TCP 握手结束。


四次挥手(Four-way handshake)：
TCP 的连接的拆除需要发送四个包，因此称为四次挥手(Four-way handshake)，也叫做改进的三次握手。
客户端或服务器均可主动发起挥手动作，在 socket 编程中，任何一方执行 close() 操作即可产生挥手操作。

第一次挥手(FIN=1，seq=x)
假设客户端想要关闭连接，客户端发送一个 FIN 标志位置为1的包，表示自己已经没有数据可以发送了，但是仍然可以接受数据。
发送完毕后，客户端进入 FIN_WAIT_1 状态。

第二次挥手(ACK=1，ACKnum=x+1)
服务器端确认客户端的 FIN 包，发送一个确认包，表明自己接受到了客户端关闭连接的请求，但还没有准备好关闭连接。
发送完毕后，服务器端进入 CLOSE_WAIT 状态，客户端接收到这个确认包之后，进入 FIN_WAIT_2 状态，等待服务器端关闭连接。

第三次挥手(FIN=1，seq=y)
服务器端准备好关闭连接时，向客户端发送结束连接请求，FIN 置为1。
发送完毕后，服务器端进入 LAST_ACK 状态，等待来自客户端的最后一个ACK。

第四次挥手(ACK=1，ACKnum=y+1)
客户端接收到来自服务器端的关闭请求，发送一个确认包，并进入 TIME_WAIT状态，等待可能出现的要求重传的 ACK 包。
服务器端接收到这个确认包之后，关闭连接，进入 CLOSED 状态。
客户端等待了某个固定时间（两个最大段生命周期，2MSL，2 Maximum Segment Lifetime）之后，
没有收到服务器端的 ACK ，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入 CLOSED 状态。
```

## TCP 和 UDP 的区别？
```
- [TCP和UDP的最完整的区别](https://blog.csdn.net/Li_Ning_/article/details/52117463)
TCP与UDP基本区别
  1.基于连接与无连接
  2.TCP要求系统资源较多，UDP较少； 
  3.UDP程序结构较简单 
  4.流模式（TCP）与数据报模式(UDP); 
  5.TCP保证数据正确性，UDP可能丢包 
  6.TCP保证数据顺序，UDP不保证 
　　
UDP应用场景：
  1.面向数据报方式
  2.网络数据大多为短消息 
  3.拥有大量Client
  4.对数据安全性无特殊要求
  5.网络负担非常重，但对响应速度要求高
```

## 什么是粘包？ socket 中造成粘包的原因是什么？ 哪些情况会发生粘包现象？
```
1. 接收方没有及时接收缓冲区的包，造成多个包接收（客户端发送了一段数据，服务端只收了一小部分，服务端下次再收的时候还是从缓冲区拿上次遗留的数据，产生粘包）
2. 发送端需要等缓冲区满才发送出去，造成粘包（发送数据时间间隔很短，数据也很小，会合到一起，产生粘包）
```

## 怎么理解分布式、高并发、多线程
```
分布式更多的一个概念，是为了解决单个物理服务器容量和性能瓶颈问题而采用的优化手段。
该领域需要解决的问题极多，在不同的技术层面上，又包括：分布式文件系统、分布式缓存、分布式数据库、分布式计算等，一些名词如Hadoop、zookeeper、MQ等都跟分布式有关。
从理念上讲，分布式的实现有两种形式：
水平扩展：当一台机器扛不住流量时，就通过添加机器的方式，将流量平分到所有服务器上，所有机器都可以提供相当的服务；
垂直拆分：前端有多种查询需求时，一台机器扛不住，可以将不同的需求分发到不同的机器上，比如A机器处理余票查询的请求，B机器处理支付的请求。

什么是高并发？
相对于分布式来讲，高并发在解决的问题上会集中一些，其反应的是同时有多少量：比如在线直播服务，同时有上万人观看。
高并发可以通过分布式技术去解决，将并发流量分到不同的物理服务器上。
但除此之外，还可以有很多其他优化手段：比如使用缓存系统，将所有的，静态内容放到CDN等；还可以使用多线程技术将一台服务器的服务能力最大化。

什么是多线程？
多线程是指从软件或者硬件上实现多个线程并发执行的技术，它更多的是解决CPU调度多个进程的问题，从而让这些进程看上去是同时执行（实际是交替运行的）。
这几个概念中，多线程解决的问题是最明确的，手段也是比较单一的，基本上遇到的最大问题就是线程安全。
在JAVA语言中，需要对JVM内存模型、指令重排等深入了解，才能写出一份高质量的多线程代码。

总结一下：
分布式是从物理资源的角度去将不同的机器组成一个整体对外服务，技术范围非常广且难度非常大，有了这个基础，高并发、高吞吐等系统很容易构建；
高并发是从业务角度去描述系统的能力，实现高并发的手段可以采用分布式，也可以采用诸如缓存、CDN等，当然也包括多线程；
多线程则聚焦于如何使用编程语言将CPU调度能力最大化。

- [怎么理解分布式、高并发、多线程？（含面试题和答案解析）](https://www.toutiao.com/a6719751407370502669/?tt_from=weixin&utm_campaign=client_share&wxshare_count=1&timestamp=1567380632&app=news_article&utm_source=weixin&utm_medium=toutiao_android&req_id=20190902073032010022057033239B5B9&group_id=6719751407370502669)
```

## django中间件， django中间件的执行顺序
```
什么是 middleware
Middlewares 是修改 Django request 或者 response 对象的钩子.

什么时候使用 middleware
如果你想修改请求，例如被传送到view中的HttpRequest对象。 或者你想修改view返回的HttpResponse对象，这些都可以通过中间件来实现。
可能你还想在view执行之前做一些操作，这种情况就可以用 middleware来实现。

多个中间件的执行顺序
在请求视图被处理前，中间件由上至下依次执行
在请求视图被处理后，中间件由下至上依次执行

总结：中间件的本质其实就是个装饰器，对于装饰器我之前的随笔里也详细说过，装饰器的本质其实就是个闭包

中间件可以定义五个方法，分别是：（主要的是process_request和process_response）
process_request(self,request)
process_view(self, request, view_func, view_args, view_kwargs)
process_template_response(self,request,response)
process_exception(self, request, exception)
process_response(self, request, response)
以上方法的返回值可以是None或一个HttpResponse对象，
如果是None，则继续按django定义的规则向后继续执行，如果是HttpResponse对象，则直接将该对象返回给用户。
```

## post和get的区别。
```
GET 用于信息获取，而且应该是安全的 和 幂等的。
所谓安全的意味着该操作用于获取信息而非修改信息。
换句话说，GET 请求一般不应产生副作用。
就是说，它仅仅是获取资源信息，就像数据库查询一样，不会修改，增加数据，不会影响资源的状态。
幂等的意味着对同一 URL 的多个请求应该返回同样的结果。

POST 表示可能修改变服务器上的资源的请求。

GET 可提交的数据量受到URL长度的限制，HTTP 协议规范没有对 URL 长度进行限制。这个限制是特定的浏览器及服务器对它的限制
理论上讲，POST 是没有大小限制的，HTTP 协议规范也没有进行大小限制，出于安全考虑，服务器软件在实现时会做一定限制
参考上面的报文示例，可以发现 GET 和 POST 数据内容是一模一样的，只是位置不同，一个在 URL 里，一个在 HTTP 包的包体里


```

## 什么是wsgi，uwsgi，uWSGI？
```
WSGI：全称是Web Server Gateway Interface，WSGI不是服务器，python模块，框架，API或者任何软件，
只是一种规范，描述web server如何与web application通信的规范。
server和application的规范在PEP 3333中有具体描述。
要实现WSGI协议，必须同时实现web server和web application，当前运行在WSGI协议之上的web框架有Bottle, Flask, Django。

uwsgi：与WSGI一样是一种通信协议，是uWSGI服务器的独占协议，用于定义传输信息的类型(type of information)，
每一个uwsgi packet前4byte为传输信息类型的描述，与WSGI协议是两种东西，据说该协议是fcgi协议的10倍快。

uWSGI：是一个web服务器，实现了WSGI协议、uwsgi协议、http协议等。

WSGI协议主要包括server和application两部分：
WSGI server负责从客户端接收请求，将request转发给application，将application返回的response返回给客户端；
WSGI application接收由server转发的request，处理请求，并将处理结果返回给server。
    application中可以包括多个栈式的中间件(middlewares)，这些中间件需要同时实现server与application，
    因此可以在WSGI服务器与WSGI应用之间起调节作用：对服务器来说，中间件扮演应用程序，对应用程序来说，中间件扮演服务器。
WSGI协议其实是定义了一种server与application解耦的规范，即可以有多个实现WSGI server的服务器，
也可以有多个实现WSGI application的框架，那么就可以选择任意的server和application组合实现自己的web应用。
例如uWSGI和Gunicorn都是实现了WSGI server协议的服务器，Django，Flask是实现了WSGI application协议的web框架，可以根据项目实际情况搭配使用。

Nginx是一个Web服务器其中的HTTP服务器功能和uWSGI功能很类似，但是Nginx还可以用作更多用途，比如最常用的反向代理功能。

- [做python Web开发你要理解：WSGI & uwsgi](https://www.jianshu.com/p/679dee0a4193)

```

## 对uWSGI和nginx的理解。
```
- [谈一下你对 uWSGI 和 nginx 的理解??](https://www.cnblogs.com/lmh001/p/9742330.html)
1.uWSGI 是一个 Web 服务器，它实现了 WSGI 协议、uwsgi、http 等协议。
Nginx 中HttpUwsgiModule 的作用是与 uWSGI 服务器进行交换。
WSGI 是一种 Web 服务器网关接口。它是一个 Web 服务器（如 nginx，uWSGI 等服务器）与 web 应用（如用 Flask 框架写的程序）通信的一种规范。
要注意 WSGI / uwsgi / uWSGI 这三个概念的区分。WSGI 是一种通信协议。
uwsgi 是一种线路协议而不是通信协议，在此常用于在 uWSGI 服务器与其他网络服务器的数据通uWSGI 是实现了 uwsgi 和 WSGI 两种协议的 Web 服务器。

2. nginx 是一个开源的高性能的 HTTP 服务器和反向代理：
　　1.作为 web 服务器，它处理静态文件和索引文件效果非常高；
　　 2.它的设计非常注重效率，最大支持 5 万个并发连接，但只占用很少的内存空间；
　　3.稳定性高，配置简洁；
　　4.强大的反向代理和负载均衡功能，平衡集群中各个服务器的负载压力应用。

nginx 和 uWISG 服务器之间如何配合工作的？
首先浏览器发起 http 请求到 nginx 服务器，Nginx 根据接收到请求包，
进行 url 分析，判断访问的资源类型，如果是静态资源，直接读取静态资源返回给浏览器，
如果请求的是动态资源就转交给 uwsgi服务器，uwsgi 服务器根据自身的 uwsgi 和 WSGI 协议，
找到对应的 Django 框架，Django 框架下的应用进行逻辑处理后，将返回值发送到 uwsgi 服务器，
然后 uwsgi 服务器再返回给 nginx，最后 nginx将返回值返回给浏览器进行渲染显示给用户。
```

## 请给出你熟悉关系数据库范式有那些，有什么作用？

## 数据库优化
```
性能优化：
        确定结果只有一条使用limit 1。
        为搜索字段建索引。 
        永远为每张表设置一个ID。
        固定长度的表会更快。
        垂直分割、水平分割。
        越小的列会越快。
        正确选择存储引擎。
        
    索引优化：
        最左前缀（匹配直到遇到范围查询(>、<、between、like)就停止匹配）
        尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1。
        索引列不能参与计算。
        尽量的扩展索引，不要新建索引。
        
    查询慢优化基本步骤：
        0.先运行看看是否真的很慢，注意设置SQL_NO_CACHE
        1.where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高
        2.explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）
        3.order by limit 形式的sql语句让排序的表优先查
        4.了解业务方使用场景
        5.加索引时参照建索引的几大原则
        6.观察结果，不符合预期继续从0分析

1. 最左前缀匹配
2. 扩展现有的索引列
3. 查询时，知道只有一条数据，使用 limit 1; 当只要一行数据时使用 LIMIT 1
4. 为搜索字段建立索引。
5. 在Join表的时候使用相当类型的例，并将其索引。
6. 避免 SELECT *，会增加网络传输的负载。
7. 永远为每张表设置一个ID
8. 尽可能的使用 NOT NULL
9. 越小的列会越快
10. 垂直分割
11. 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1
12. 索引列不能参与计算

## 慢查询优化基本步骤
0.先运行看看是否真的很慢，注意设置SQL_NO_CACHE
1.where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高
2.explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）
3.order by limit 形式的sql语句让排序的表优先查
4.了解业务方使用场景
5.加索引时参照建索引的几大原则
6.观察结果，不符合预期继续从0分析
```

## 百万级日活量，数据库设计：
```
分库设计： 分多台机器（订单 id 来 hash 后按 5 取模， hash(id) % 5， 查询的时候，也可以通过订单 id 来 hash 取模），
分表设计： 大量分表来保证海量数据下的查询性能，  每台机器然后分1024张表，然后继续取模，

在写入数据的时候，需要做两次路由，先对订单 id hash 后对数据库的数量取模，可以路由到一台数据库上，然后再对那台数据库上的表数量取模，就可以路由到数据库上的一个表里了。

通过这个步骤，就可以让每个表里的数据量非常小，每年 1 亿数据增长，但是到每个表里才 10 万条数据增长，这个系统运行 10 年，每个表里可能才百万级的数据量。

如何保证订单ID唯一：
方案一：独立数据库自增 id（不能满足高并发）
方案二：UUID（uuid太长，作为主键来性能不好）
方案三：获取系统当前时间  SnowFlake 算法

读写分离来支撑按需扩容以及性能提升

高并发下的数据库架构设计总结
从大的一个简化的角度来说，高并发的场景下，数据库层面的架构肯定是需要经过精心的设计的。

尤其是涉及到分库来支撑高并发的请求，大量分表保证每个表的数据量别太大，读写分离实现主库和从库按需扩容以及性能保证。

这篇文章就是从一个大的角度来梳理了一下思路，各位同学可以结合自己公司的业务和项目来考虑自己的系统如何做分库分表。

另外就是，具体的分库分表落地的时候，需要借助数据库中间件来实现分库分表和读写分离，大家可以自己参考 Sharding-JDBC 或者 MyCAT 的官网即可，里面的文档都有详细的使用描述。
```

## 对cookie和session的理解？他们能单独用吗？
```
cookie只是实现session的其中一种方案。虽然是最常用的，但并不是唯一的方法。禁用cookie后还有其他方法存储，比如放在url中
现在大多都是Session + Cookie，但是只用session不用cookie，或是只用cookie，不用session在理论上都可以保持会话状态。可是实际中因为多种原因，一般不会单独使用
用session只需要在客户端保存一个id，实际上大量数据都是保存在服务端。如果全部用cookie，数据量大的时候客户端是没有那么多空间的。
如果只用cookie不用session，那么账户信息全部保存在客户端，一旦被劫持，全部信息都会泄露。并且客户端数据量变大，网络传输的数据量也会变大

简而言之, session 有如用户信息档案表, 里面包含了用户的认证信息和登录状态等信息. 而 cookie 就是用户通行证。

session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session。依赖cookie
cookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。
token也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户。需要开发者手动添加。
jwt只是一个跨域认证的方案

在大型互联网系统中，单独使用 Cookie 和 Session 都是不可行的，原因很简单。
因为如果使用 Cookie，可以很好地解决应用的分布式部署问题，大型互联网应用系统一个应用有上百台机器，
而且有很多不同的应用系统协同工作，由于 Cookie 是将值存储在客户端的浏览器里，
用户每次访问都会将最新的值带回给处理该请求的服务器，所以也就解决了同一个用户的请求可能不在同一台服务器处理而导致的 Cookie 不一致的问题。
```

## HTTPS是如何实现安全传输数据的？

## 悲观锁和乐观锁是什么？
```
- [乐观锁、悲观锁，这一篇就够了！](https://segmentfault.com/a/1190000016611415)
```

## 微服务架构

# 排序算法
```
############################################################
1. 冒泡排序原理：
从左到右先找第一个值，然后拿这个值右边的值和它进行比较，假如右边的值比它小，那就将右边的这个值和它进行交换，
这样，就能够将整个列表中最小的值放到最左边，第一次排序完成，之后对第二个数也进行相同的操作，最终整个列表变成有序的。
冒泡排序法的时间复杂度是O(n**2),是一种稳定排序算法，逻辑比较简单。
def MaopaoSort(lst):
    lg = len(lst)
    for i in xrange(lg):
        for j in xrange(i, lg):
            if lst[i]>lst[j]:
                lst[i], lst[j] = lst[j], lst[i]

if __name__ == "__main__":
    list1 = [1, 3, 2, 5, 4, 0]
    MaopaoSort(list1)
    print list1
############################################################
2. 希尔排序原理：
    在序列中，找到一个中间的位置，然后将该序列分成左右两个序列，
再将左边序列第一个值与右边序列第一个值进行比较，如果左边大于右边，则进行交换，持续下去，
将左右两个序列比较完成后，左右两个序列又分别取中间位置，分成4个序列，再分别在这四个序列中取出第一个数，
进行比较，使得四个序列的第一个数是按照从小到大排列的，这样依次下去，直到把四个序列的值都对比完成后，
再从这四个序列中再取中间数，将四个序列拆成八个序列，在进行比较，
到最后，拆成的序列数量为原来序列长度的一半的时候，原来序列中奇数位置的值都有序了，偶数位置的值也都有序了，
这时候再进行最后一次比较，拆出的序列数量等于原来序列长度，这时候再经过一次排序，整个序列有序了。
希尔排序的时间复杂度是O(nlog2n),是一种不稳定的排序算法，逻辑比较复杂。
def shellsort(lst):
    length = len(lst)
    grep = length//2
    while grep:
        for i in range(grep, length):
            # 类似插入排序, 当前值与指定步长之前的值比较, 符合条件则交换位置
            while i>=grep and lst[i-grep]>lst[i]:
                lst[i-grep], lst[i] = lst[i], lst[i-grep]
                i -= grep
        grep = grep//2

if __name__ == "__main__":
    list1 = [1, 3, 2, 5, 4, 0]
    shellsort(list1)
    print list1

############################################################
3. 归并排序原理：
归并排序是基于对两个有序序列进行排序变成新的有序序列的方式进行排序的，假如有两个有序序列，从第一个值开始一个一个比较，
小的就插入到新的序列中，并使得其位置加一，最后，两个序列中会有某一个序列还剩下最大值，将该最大值插入到新的序列中就完成了排序。
归并排序使用递归方式将一个序列从中间分成左右两个序列，再将左右两个序列从中间分成四个序列。
递归下去最后分到每个序列中只有一个元素，将这个元素返回，到上一级调用两序列排序方式，将两个值排序，返回新的排序好的序列，
就这样一层一层递归上来，最后使得序列有序。该方式是使用空间换取排序时间的算法。
归并排序的时间复杂度是O(nlog2n),是一种稳定的算法，逻辑比较复杂
def merge_sort(alist):
    length = len(alist)
    if length<2: return alist
    arr1 = merge_sort(alist[:length>>1])
    arr2 = merge_sort(alist[length>>1:])
    return merge_list(arr1, arr2)

def merge_list(alist1, alist2):
    i, j, T = 0, 0, []
    while i < len(alist1) and j < len(alist2):
        if alist1[i] <= alist2[j]:
            T.append(alist1[i])
            i += 1
        else:
            T.append(alist2[j])
            j += 1
    T.extend(alist1[i:])
    T.extend(alist2[j:])
    return T

def main():
    alist = [54,26,93,17,77,31,44,55,20]
    merge_sort(alist)

############################################################
4. 快速排序原理：
在序列中找到一个定位点（一般是第一个点）然后将比这个点的值大的值挪到它的右边，比这个值小的值挪到它的左边，最后返回 该点的位置。
通过递归调用该方法，将序列分成左右两个序列，然后再细分下去，到最后每个序列中只有两个元素，这两个元素被排好序后返回到上一层，最后返回的将是排序好的序列。
快速排序的时间复杂度是O(nlog2n)，最坏情况时间复杂度O(n**2),是一种不稳定的算法，逻辑比较复杂
其实快速排序想要进行优化的话，要找到一个合适的定位点，这个定位点如果总是第一个点的话，当这个点取到的值是最大的值，之后假如每次递归取到的第一个点都是最大的值，
那么，这就是快速排序最坏的情况了，这时候。。。递归树就变成了一个序列了。。。是一颗非常不平衡的树。
但是如果每次找这个点之前能找到一个合适的点的话，就能够使得递归树变成一颗平衡树，这样就能达到快速排序的最好情况。
所以，优化就在这个定位点的选取上，如果总是能把定位点选取合适，那么快速排序是一个非常好的稳定的排序算法。

快速排序算法速度非常快，但是还是比list内置排序法时间上慢了一个数量级，但是，比归并排序少了一半左右的时间，至于为什么比快速排序要快。。。这个我目前还没有找到好的解释办法。。。

快速排序也是一种分治思想，基本思想是先随便在无序列表中找一个元素，以这个元素为基准，其他所有元素都跟该元素比，
比该元素小的成为一个子序列，比该元素大的成为另一个子序列，接着重复此过程，最终达到排序效果。我们也用递归的方式来实现。

快速排序使用分治法（Divide and conquer）策略来把一个序列（list）分为两个子序列（sub-lists）。
步骤
1. 从数列中挑出一个元素，称为”基准”（pivot），
2. 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。
3. 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。

def quik_sort(lst):
    if len(lst)<2: return lst
    pivot = lst[0]
    return (
        quik_sort([i for i in lst[1:] if i<pivot]) +
        [pivot] +
        quik_sort([i for i in lst[1:] if i>=pivot])
    )

if __name__ == "__main__":
    list1 = [1, 3, 2, 5, 4, 0]
    list2 = quik_sort(list1)
    print list2

############################################################
5. 选择排序 基本思想：
从未排序的序列中找到一个最小的元素，放到第一位，再从剩余未排序的序列中找到最小的元素，放到第二位，依此类推，直到所有元素都已排序完毕。
假设序列元素总共n+1个，则我们需要找n轮，就可以使该序列排好序。
在每轮中，我们可以这样做：
    用未排序序列的第一个元素和后续的元素依次相比较，如果后续元素小，则后续元素和第一个元素交换位置放到，这样一轮后，排在第一位的一定是最小的。这样进行n轮，就可排序。

选择排序（Selection sort）是一种简单直观的排序算法。它的工作原理大致是将后面的元素最小元素一个个取出然后按顺序放置。
步骤：
1. 在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，
2. 再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。
3. 重复第二步，直到所有元素均排序完毕。
def select_sort(arr):
    length = len(arr)
    for i in xrange(0, length):
        min = i
        for j in range(i+1, length):
            if arr[j] < arr[min]:
                min=j
                arr[min], arr[i] = arr[i], arr[min]
    return arr

if __name__ == "__main__":
    list1 = [1, 3, 2, 5, 4]
    list1=select_sort(list1)
    print list1
```

## 二分查找
```
# coding=utf-8
#  O( log^n )

def binary_search(alist, item):
    length = len(alist)
    if not length:
        return False
    mid = length//2
    if alist[mid]==item:
        return True
    if alist[mid]>item:
        return binary_search(alist[:mid], item)
    else:
        return binary_search(alist[mid+1:], item)

testlist = [0, 1, 2, 8, 13, 17, 19, 32, 42,]
print(binary_search(testlist, 3))
print(binary_search(testlist, 13))

# 1. 从列表中找出[1, 7, 22, 33, 55, 66, 99, 101]找出99的位置
# 二分查找，用于在较大的数据列表中查询某个值，考虑到元素比较多，单纯的遍历会造成内存压力过大，考虑使用二分查找
# 二分查找的关键在于查询中间值，将需要查找的值与中间值进行比较，然后确定查找方向
def binary_search_index(alist, value, start=0):
    length = len(alist)
    if not length:
        return -1
    mid = length//2
    if alist[mid] == value:
        return start + mid
    elif value<alist[mid]:
        return binary_search_index(alist[:mid], value, start)
    else:
        return binary_search_index(alist[mid+1:], value, start+mid+1)

testlist = [0, 1, 2, 8, 13, 17, 19, 32, 42,]
testlist = [1, 7, 22, 33, 55, 66, 99, 101]
print(binary_search_index(testlist, 8))
print(binary_search_index(testlist, 22))
print(binary_search_index(testlist, 99))

# False
# True
# -1
# 2
# 6
```

## 链表、排序、最短距离（最小生成树）
     

## 多线程是不是共用栈内存？

## 堆内存/栈内存的区别。

## set/dict 访问为啥会快，底层是怎么实现的？

## 算法练习。 首先熟悉基本的数据结构与算法。

     